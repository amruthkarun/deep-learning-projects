{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nAuthor: Amruth Karun M V\nDate: 12-Oct-2021\n\"\"\"\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport zipfile\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (\n    Dense, Activation, Dropout, Flatten, \n    Conv2D, MaxPooling2D, BatchNormalization\n)\n\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nTRAIN_PATH = \"../input/cifar10/cifar10/train\"\nTEST_PATH = \"../input/cifar10/cifar10/test\"\nEPOCHS = 100\nBATCH_SIZE = 256\nLEARNING_RATE = 0.001\n\n\ndef load_data(input_path, shuffle=False):\n    \"\"\"\n    Loads input data fro directory\n    Arguments:\n        input_path -- input data path\n        shuffle    -- whether data needs to be shuffled or not\n    Returns: Data generator\n    \"\"\"\n    \n    data_generator = keras.preprocessing.image.ImageDataGenerator()\n    data_generator = data_generator.flow_from_directory(directory=input_path, target_size=(224,224), shuffle=shuffle)\n    \n    return data_generator\n\n\ndef load_model():\n    \"\"\"\n    Creates a keras VGG-16 model\n    Arguments: None\n    Returns: VGG-16 Model\n    \"\"\"\n    \n    model = Sequential()\n    model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n    \n    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n\n    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n    \n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n    \n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n    \n    model.add(Flatten())\n    model.add(Dense(units=4096,activation=\"relu\"))\n    model.add(Dense(units=4096,activation=\"relu\"))\n    model.add(Dense(units=10, activation=\"softmax\"))\n    model.summary()\n   \n    opt = Adam(lr=LEARNING_RATE)\n    model.compile(loss = keras.losses.categorical_crossentropy, optimizer=opt,\n    metrics=['accuracy'])\n    \n    return model\n\n\ndef plot_curves(history):\n    \"\"\"\n    Plots loss and accuracy and loss plots for\n    training and validation datasets\n    Arguments: \n        history -- training history\n    Returns: None\n    \"\"\"\n   \n    plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n    plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n    plt.xticks(np.arange(1, EPOCHS, 10))\n    plt.legend()\n    plt.title('Training Loss VS Validation Loss')\n    plt.show()\n    \n    plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n    plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n    plt.xticks(np.arange(1, EPOCHS, 10))\n    plt.title('Training Accuracy VS Validation Accuracy')\n    plt.legend()\n    plt.show()\n    \n\ndef get_confusion_matrix(model, input_path):\n    \"\"\"\n    Calculates the confusion matrix\n    for the input data\n    Arguments:\n        model       -- trained model\n        input_path  -- input data path\n    Returns: None\n    \"\"\"\n\n    data_generator = load_data(input_path)\n    predictions = model.predict(data_generator, BATCH_SIZE)\n    y_pred = np.argmax(predictions, axis=1)\n    y_true = data_generator.classes\n    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\n    print(\"Accuracy score = \", metrics.accuracy_score(y_true, y_pred))\n    cm = metrics.confusion_matrix(y_true, y_pred)\n    metrics.ConfusionMatrixDisplay(cm, display_labels=class_names).plot(cmap=plt.cm.Blues,\n                                                                       xticks_rotation='vertical')\n    plt.show()\n\n    \ndef train_model():\n    \"\"\"\n    Trains VGG-16 model and saves the \n    trained weights to an H5 file.\n    Arguments: None\n    Returns: None\n    \"\"\"\n    \n    train_generator = load_data(TRAIN_PATH, True)\n    val_generator = load_data(TEST_PATH, True)\n    \n    # Loads VGG-16 model\n    model = load_model()\n    earlystop = keras.callbacks.EarlyStopping(patience=20)\n    callbacks = [earlystop]\n    \n    history = model.fit(\n        train_generator, \n        batch_size=BATCH_SIZE,\n        epochs=EPOCHS,\n        validation_data=val_generator,\n        validation_steps=val_generator.samples//BATCH_SIZE,\n        steps_per_epoch=train_generator.samples//BATCH_SIZE,\n        callbacks=callbacks)\n    \n    plot_curves(history)\n    model.save_weights(\"model_vgg16.h5\")\n    print(\"Model saved successfully!\")\n    \n    return model\n\n    \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-11T17:37:15.256175Z","iopub.execute_input":"2021-10-11T17:37:15.256504Z","iopub.status.idle":"2021-10-11T17:37:15.304062Z","shell.execute_reply.started":"2021-10-11T17:37:15.25647Z","shell.execute_reply":"2021-10-11T17:37:15.303177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nmodel = train_model()\nprint(\"Confusion matrix for train data: \")\nget_confusion_matrix(model, TRAIN_PATH)\nprint(\"Confusion matrix for val data: \")\nget_confusion_matrix(model, TEST_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T04:36:28.496349Z","iopub.execute_input":"2021-10-11T04:36:28.496682Z","iopub.status.idle":"2021-10-11T04:38:38.068986Z","shell.execute_reply.started":"2021-10-11T04:36:28.496646Z","shell.execute_reply":"2021-10-11T04:38:38.067105Z"},"trusted":true},"execution_count":null,"outputs":[]}]}