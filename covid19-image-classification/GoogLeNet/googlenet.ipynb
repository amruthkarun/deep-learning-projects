{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nAuthor: Amruth Karun M V\nDate: 19-Oct-2021\n\"\"\"\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport zipfile\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input, Conv2D, MaxPool2D,\n    AveragePooling2D, Flatten, GlobalAveragePooling2D,\n    Dense, Dropout)\nfrom keras.layers.merge import concatenate\n\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nTRAIN_PATH = \"../input/covid19/\"\nEPOCHS = 100\nBATCH_SIZE = 128\nLEARNING_RATE = 0.001\nINPUT_SIZE = (224, 224)\n\ndef load_data():\n    \"\"\"\n    Loads input data from directory\n    Arguments: None\n    Returns: Train and val generator\n    \"\"\"\n    \n    train_datagen =  keras.preprocessing.image.ImageDataGenerator(validation_split=0.2) # set validation split\n\n    train_generator = train_datagen.flow_from_directory(\n        TRAIN_PATH,\n        target_size=INPUT_SIZE,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        class_mode='categorical',\n        subset='training') # set as training data\n\n    validation_generator = train_datagen.flow_from_directory(\n        TRAIN_PATH, \n        target_size=INPUT_SIZE,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        class_mode='categorical',\n        subset='validation') # set as validation data\n    \n    return train_generator, validation_generator\n\n\ndef inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, \n                     filters_5x5_reduce, filters_5x5,filters_pool_proj,\n                     name=None): \n    \"\"\"\n    Represents an inception block\n    Arguments:\n        x                                     -- input\n        filters_1x1                           -- number of filters of the 1x1 convolutional \n                                                 layer in the first path\n        filters_3x3_reduce, filters_3x3       -- number of filters corresponding to the 1x1 \n                                                 and 3x3 convolutional layers in the second path\n        filters_5x5_reduce, filters_pool_proj -- number of filters corresponding to the 1x1 and \n                                                 5x5  convolutional layer in the third path\n        filters_pool_proj                     -- number of filters of the 1x1 convolutional layer\n    Returns: output layer\n    \"\"\"\n    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n    \n    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu')(conv_3x3)\n\n    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu')(conv_5x5)\n\n    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu')(pool_proj)\n\n    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n    \n    return output\n\n\ndef load_model():\n    \"\"\"\n    Creates a keras GoogleNet model\n    Arguments: None\n    Returns: GoogleNet Model\n    \"\"\"\n    \n    input_layer = Input(shape=(224, 224, 3))\n\n    x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2')(input_layer)\n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n    x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n    x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n\n    x = inception_module(x,\n                     filters_1x1=64,\n                     filters_3x3_reduce=96,\n                     filters_3x3=128,\n                     filters_5x5_reduce=16,\n                     filters_5x5=32,\n                     filters_pool_proj=32,\n                     name='inception_3a')\n\n    x = inception_module(x,\n                     filters_1x1=128,\n                     filters_3x3_reduce=128,\n                     filters_3x3=192,\n                     filters_5x5_reduce=32,\n                     filters_5x5=96,\n                     filters_pool_proj=64,\n                     name='inception_3b')\n\n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n\n    x = inception_module(x,\n                     filters_1x1=192,\n                     filters_3x3_reduce=96,\n                     filters_3x3=208,\n                     filters_5x5_reduce=16,\n                     filters_5x5=48,\n                     filters_pool_proj=64,\n                     name='inception_4a')\n\n\n    x1 = AveragePooling2D((5, 5), strides=3)(x)\n    x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n    x1 = Flatten()(x1)\n    x1 = Dense(1024, activation='relu')(x1)\n    x1 = Dropout(0.7)(x1)\n    x1 = Dense(3, activation='softmax', name='auxilliary_output_1')(x1)\n\n    x = inception_module(x,\n                     filters_1x1=160,\n                     filters_3x3_reduce=112,\n                     filters_3x3=224,\n                     filters_5x5_reduce=24,\n                     filters_5x5=64,\n                     filters_pool_proj=64,\n                     name='inception_4b')\n\n    x = inception_module(x,\n                     filters_1x1=128,\n                     filters_3x3_reduce=128,\n                     filters_3x3=256,\n                     filters_5x5_reduce=24,\n                     filters_5x5=64,\n                     filters_pool_proj=64,\n                     name='inception_4c')\n\n    x = inception_module(x,\n                     filters_1x1=112,\n                     filters_3x3_reduce=144,\n                     filters_3x3=288,\n                     filters_5x5_reduce=32,\n                     filters_5x5=64,\n                     filters_pool_proj=64,\n                     name='inception_4d')\n\n\n    x2 = AveragePooling2D((5, 5), strides=3)(x)\n    x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n    x2 = Flatten()(x2)\n    x2 = Dense(1024, activation='relu')(x2)\n    x2 = Dropout(0.7)(x2)\n    x2 = Dense(3, activation='softmax', name='auxilliary_output_2')(x2)\n\n    x = inception_module(x,\n                     filters_1x1=256,\n                     filters_3x3_reduce=160,\n                     filters_3x3=320,\n                     filters_5x5_reduce=32,\n                     filters_5x5=128,\n                     filters_pool_proj=128,\n                     name='inception_4e')\n\n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n\n    x = inception_module(x,\n                     filters_1x1=256,\n                     filters_3x3_reduce=160,\n                     filters_3x3=320,\n                     filters_5x5_reduce=32,\n                     filters_5x5=128,\n                     filters_pool_proj=128,\n                     name='inception_5a')\n\n    x = inception_module(x,\n                     filters_1x1=384,\n                     filters_3x3_reduce=192,\n                     filters_3x3=384,\n                     filters_5x5_reduce=48,\n                     filters_5x5=128,\n                     filters_pool_proj=128,\n                     name='inception_5b')\n\n    x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n\n    x = Dropout(0.4)(x)\n\n    x = Dense(3, activation='softmax', name='output')(x)\n    model = Model(input_layer, [x, x1, x2], name='GoogLeNet')\n    model.summary()\n    \n    opt = Adam(learning_rate=LEARNING_RATE)\n    model.compile(loss = keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n    return model\n\n\ndef plot_curves(history):\n    \"\"\"\n    Plots loss and accuracy and loss plots for\n    training and validation datasets\n    Arguments: \n        history -- training history\n    Returns: None\n    \"\"\"\n   \n    plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n    plt.plot(history.history['val_loss'], color='r', label=\"Validation loss\")\n    plt.legend()\n    plt.title('Training Loss VS Validation Loss')\n    plt.show()\n    \n    plt.plot(history.history['output_accuracy'], color='b', label=\"Training accuracy\")\n    plt.plot(history.history['val_output_accuracy'], color='r',label=\"Validation accuracy\")\n    plt.title('Training Accuracy VS Validation Accuracy')\n    plt.legend()\n    plt.show()\n    \n\ndef get_confusion_matrix(model, data_generator):\n    \"\"\"\n    Calculates the accuracy and displays the \n    confusion matrix for the input data\n    Arguments:\n        model           -- trained model\n        data_generator  -- input data generator\n    Returns: None\n    \"\"\"\n    \n    predictions = model.predict(data_generator, BATCH_SIZE)\n    y_pred = np.argmax(predictions[0], axis=1)\n    y_true = data_generator.classes\n    class_names = ['COVID', 'Normal', 'Pneumonia']\n    \n    print(\"Score =\", model.evaluate(data_generator, batch_size=BATCH_SIZE))\n    print(\"Accuracy  = \", metrics.accuracy_score(y_true, y_pred))\n    cm = metrics.confusion_matrix(y_true, y_pred)\n    metrics.ConfusionMatrixDisplay(cm, display_labels=class_names).plot(cmap=plt.cm.Blues,\n                                                                       xticks_rotation='vertical')\n    plt.show()\n\n    \ndef train_model(train_generator, val_generator):\n    \"\"\"\n    Trains GoogleNet model and saves the \n    trained weights to an H5 file.\n    Arguments: \n        train_generator   -- train data generator\n        val_generator     -- validation data generator\n    Returns: Trained model\n    \"\"\"\n    \n    # Loads the model\n    model = load_model()\n    earlystop = keras.callbacks.EarlyStopping(patience=10)\n    callbacks = [earlystop]\n    \n    history = model.fit(\n        train_generator, \n        batch_size=BATCH_SIZE,\n        epochs=EPOCHS,\n        validation_data=val_generator,\n        validation_steps=val_generator.samples//BATCH_SIZE,\n        steps_per_epoch=train_generator.samples//BATCH_SIZE,\n        callbacks=callbacks)\n    \n    plot_curves(history)\n    model.save_weights(\"model.h5\")\n    print(\"Model saved successfully!\")\n    \n    return model\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-19T06:35:33.44686Z","iopub.execute_input":"2021-10-19T06:35:33.447208Z","iopub.status.idle":"2021-10-19T06:35:39.009072Z","shell.execute_reply.started":"2021-10-19T06:35:33.4471Z","shell.execute_reply":"2021-10-19T06:35:39.008347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator, val_generator = load_data()\nmodel = train_model(train_generator, val_generator)\n\nprint(\"Confusion matrix for train data:\")\nget_confusion_matrix(model, train_generator)\n\nprint(\"Confusion matrix for val/test data:\")\nget_confusion_matrix(model, val_generator)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T06:35:39.010753Z","iopub.execute_input":"2021-10-19T06:35:39.010992Z","iopub.status.idle":"2021-10-19T06:38:40.494729Z","shell.execute_reply.started":"2021-10-19T06:35:39.010956Z","shell.execute_reply":"2021-10-19T06:38:40.494029Z"},"trusted":true},"execution_count":null,"outputs":[]}]}