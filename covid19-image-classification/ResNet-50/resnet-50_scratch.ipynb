{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nAuthor: Amruth Karun M V\nDate: 20-Oct-2021\n\"\"\"\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport zipfile\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input, Conv2D, MaxPooling2D, Activation,\n    AveragePooling2D, Flatten, BatchNormalization,\n    Dense, Dropout, ZeroPadding2D, Add)\nfrom keras.layers.merge import concatenate\n\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nTRAIN_PATH = \"../input/covid19/\"\nEPOCHS = 100\nBATCH_SIZE = 128\nLEARNING_RATE = 0.01\nINPUT_SIZE = (224, 224)\n\ndef load_data():\n    \"\"\"\n    Loads input data from directory\n    Arguments: None\n    Returns: Train and val generator\n    \"\"\"\n    \n    train_datagen =  keras.preprocessing.image.ImageDataGenerator(validation_split=0.2) # set validation split\n\n    train_generator = train_datagen.flow_from_directory(\n        TRAIN_PATH,\n        target_size=INPUT_SIZE,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        class_mode='categorical',\n        subset='training') # set as training data\n\n    validation_generator = train_datagen.flow_from_directory(\n        TRAIN_PATH, \n        target_size=INPUT_SIZE,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        class_mode='categorical',\n        subset='validation') # set as validation data\n    \n    return train_generator, validation_generator\n\n\ndef identity_block(X, f, filters, stage, block):\n    \"\"\"\n    The identity block is the block that has no conv layer at shortcut.\n    Arguments:\n        X       -- input tensor\n        f       -- kernel size of middle conv layer at main path\n        filters -- list of integers, the filters of 3 conv layer at main path\n        stage   -- integer, current stage label, used for generating layer names\n        block   -- 'a','b'..., current block label, used for generating layer names\n    Returns: Output tensor for the block.\n    \"\"\"\n    \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    f1, f2, f3 = filters\n\n    X_shortcut = X\n   \n    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=f2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    X = Add()([X, X_shortcut])# Skip Connection\n    X = Activation('relu')(X)\n\n    return X\n\n\ndef convolutional_block(X, f, filters, stage, block, strides=(2,2)):\n    \"\"\"\n    A block that has a conv layer at shortcut.\n    Arguments:\n        X       -- input tensor\n        f       -- the kernel size of middle conv layer at main path\n        filters -- list of integers, the filters of 3 conv layer at main path\n        stage   -- integer, current stage label, used for generating layer names\n        block   -- 'a','b'..., current block label, used for generating layer names\n        strides -- strides for the first conv layer in the block.\n    Returns: Output tensor for the block.\n    \"\"\"\n    \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    f1, f2, f3 = filters\n\n    X_shortcut = X\n\n    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=strides, padding='valid', name=conv_name_base + '2a')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=f2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    X_shortcut = Conv2D(filters=f3, kernel_size=(1, 1), strides=strides, padding='valid', name=conv_name_base + '1')(X_shortcut)\n    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\n\n\ndef load_model():\n    \"\"\"\n    Creates a keras ResNet-50 model\n    Arguments: None\n    Returns: ResNet-50 Model\n    \"\"\"\n    \n    input_layer = Input(shape=(224, 224, 3))\n\n    X = ZeroPadding2D((3, 3))(input_layer)\n\n    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(X)\n    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', strides=(1,1))\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n\n    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', strides=(2,2))\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', strides=(2,2))\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', strides=(2,2))\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n    X = Dropout(0.4)(X)\n        \n    # Define fully connected layers and output\n    X = Flatten()(X)\n    X = Dense(units=512,activation=\"relu\")(X)\n    X = Dense(units=256,activation=\"relu\")(X)\n    X = Dense(units=3, activation=\"softmax\")(X)\n    \n    model = Model(inputs=input_layer, outputs=X, name='ResNet50')\n    model.summary()\n    \n    opt = Adam(learning_rate=LEARNING_RATE)\n    model.compile(loss = keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n    \n    return model    \n    \n\ndef plot_curves(history):\n    \"\"\"\n    Plots loss and accuracy and loss plots for\n    training and validation datasets\n    Arguments: \n        history -- training history\n    Returns: None\n    \"\"\"\n   \n    plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n    plt.plot(history.history['val_loss'], color='r', label=\"Validation loss\")\n    plt.legend()\n    plt.title('Training Loss VS Validation Loss')\n    plt.show()\n    \n    plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n    plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n    plt.title('Training Accuracy VS Validation Accuracy')\n    plt.legend()\n    plt.show()\n    \n\ndef get_confusion_matrix(model, data_generator):\n    \"\"\"\n    Calculates the accuracy and displays the \n    confusion matrix for the input data\n    Arguments:\n        model           -- trained model\n        data_generator  -- input data generator\n    Returns: None\n    \"\"\"\n    \n    predictions = model.predict(data_generator, BATCH_SIZE)\n    y_pred = np.argmax(predictions, axis=1)\n    y_true = data_generator.classes\n    class_names = ['COVID', 'Normal', 'Pneumonia']\n    \n    print(\"Score =\", model.evaluate(data_generator, batch_size=BATCH_SIZE))\n    print(\"Accuracy  = \", metrics.accuracy_score(y_true, y_pred))\n    cm = metrics.confusion_matrix(y_true, y_pred)\n    metrics.ConfusionMatrixDisplay(cm, display_labels=class_names).plot(cmap=plt.cm.Blues,\n                                                                       xticks_rotation='vertical')\n    plt.show()\n\n    \ndef train_model(train_generator, val_generator):\n    \"\"\"\n    Trains ResNet-50 model and saves the \n    trained weights to an H5 file.\n    Arguments: \n        train_generator   -- train data generator\n        val_generator     -- validation data generator\n    Returns: Trained model\n    \"\"\"\n    \n    # Loads the model\n    model = load_model()\n    earlystop = keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)\n    callbacks = [earlystop]\n    \n    history = model.fit(\n        train_generator, \n        batch_size=BATCH_SIZE,\n        epochs=EPOCHS,\n        validation_data=val_generator,\n        validation_steps=val_generator.samples//BATCH_SIZE,\n        steps_per_epoch=train_generator.samples//BATCH_SIZE,\n        callbacks=callbacks)\n    \n    plot_curves(history)\n    model.save_weights(\"model_resnet50.h5\")\n    print(\"Model saved successfully!\")\n    \n    return model\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-20T04:44:32.406306Z","iopub.execute_input":"2021-10-20T04:44:32.40656Z","iopub.status.idle":"2021-10-20T04:44:32.675347Z","shell.execute_reply.started":"2021-10-20T04:44:32.406532Z","shell.execute_reply":"2021-10-20T04:44:32.674485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator, val_generator = load_data()\nmodel = train_model(train_generator, val_generator)\n\nprint(\"Confusion matrix for train data:\")\nget_confusion_matrix(model, train_generator)\n\nprint(\"Confusion matrix for val/test data:\")\nget_confusion_matrix(model, val_generator)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T04:44:32.677339Z","iopub.execute_input":"2021-10-20T04:44:32.677651Z","iopub.status.idle":"2021-10-20T04:50:16.395664Z","shell.execute_reply.started":"2021-10-20T04:44:32.677613Z","shell.execute_reply":"2021-10-20T04:50:16.394924Z"},"trusted":true},"execution_count":null,"outputs":[]}]}