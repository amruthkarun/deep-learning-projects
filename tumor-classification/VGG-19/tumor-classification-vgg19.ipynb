{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nTumor Classsification using VGG-19\nAuthor: Amruth Karun M V\nDate: 07-Nov-2021\n\"\"\"\n\nimport os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Dense, Input, Dropout, Flatten, \n    Conv2D, MaxPooling2D, BatchNormalization\n)\n\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nTRAIN_PATH = \"../input/brain-tumor-mri-dataset/Training\"\nTEST_PATH = \"../input/brain-tumor-mri-dataset/Testing\"\nCLASS_NAMES = ['Glioma', 'Meningioma', 'No-tumor', 'Pituitary']\nEPOCHS = 100\nBATCH_SIZE = 128\nLEARNING_RATE = 0.001\n\n\ndef plot_sample_images():\n    \"\"\"\n    Plots sample images for each class\n    Arguments: None\n    Returns: Plots sample data\n    \"\"\"\n    \n    plt.figure(figsize=(10, 10))\n    sample_image_path = ['/glioma/Tr-gl_0010.jpg', '/meningioma/Tr-me_0010.jpg', \n                         '/notumor/Tr-no_0010.jpg', '/pituitary/Tr-pi_0010.jpg']\n    for i in range(len(CLASS_NAMES)):\n        ax = plt.subplot(2, 2, i + 1)\n        img = cv2.imread(TRAIN_PATH + sample_image_path[i])\n        img = cv2.resize(img, (128, 128))\n        plt.imshow(img)\n        plt.title(CLASS_NAMES[i])\n    \n    \ndef load_data(input_path, shuffle=False):\n    \"\"\"\n    Loads input data fro directory\n    Arguments:\n        input_path -- input data path\n        shuffle    -- whether data needs to be shuffled or not\n    Returns: Data generator\n    \"\"\"\n    \n    data_generator = keras.preprocessing.image.ImageDataGenerator()\n    data_generator = data_generator.flow_from_directory(directory=input_path, target_size=(224,224), \n                                                        shuffle=shuffle, class_mode= \"categorical\")\n    \n    return data_generator\n\n\ndef load_model():\n    \"\"\"\n    Creates a keras VGG-19 model\n    Arguments: None\n    Returns: VGG-19 Model\n    \"\"\"\n    \n    img_input = Input(shape=(224, 224, 3))\n    \n    # Block 1\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n\n    # Block 2\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n    # Block 3\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n\n    # Block 4\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n\n    # Block 5\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n    \n    # Classification block\n    x = Flatten(name='flatten')(x)\n    x = Dense(4096, activation='relu', name='fc1')(x)\n    x = Dropout(0.4)(x)\n    x = Dense(4096, activation='relu', name='fc2')(x)\n    x = Dropout(0.4)(x)\n    x = Dense(4, activation='softmax', name='predictions')(x)\n    \n    model = Model(img_input, x, name='vgg-19')\n    \n    model.summary()\n   \n    opt = Adam(learning_rate=LEARNING_RATE)\n    model.compile(loss = keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n    \n    return model\n\n\ndef plot_curves(history):\n    \"\"\"\n    Plots loss and accuracy and loss plots for\n    training and validation datasets\n    Arguments: \n        history -- training history\n    Returns: None\n    \"\"\"\n   \n    plt.plot(history.history['loss'], label=\"Training loss\")\n    plt.plot(history.history['val_loss'], label=\"Validation loss\")\n    plt.legend()\n    plt.title('Training Loss VS Validation Loss')\n    plt.show()\n    \n    plt.plot(history.history['accuracy'], label=\"Training accuracy\")\n    plt.plot(history.history['val_accuracy'], label=\"Validation accuracy\")\n    plt.title('Training Accuracy VS Validation Accuracy')\n    plt.legend()\n    plt.show()\n    \n\ndef evaluate_model(model, input_path):\n    \"\"\"\n    Evaluates the model and displays\n    the confusion matrix\n    Arguments:\n        model       -- trained model\n        input_path  -- input data path\n    Returns: Model score and confusion matrix\n    \"\"\"\n\n    data_generator = load_data(input_path)\n    predictions = model.predict(data_generator, BATCH_SIZE)\n    y_pred = np.argmax(predictions, axis=1)\n    y_true = data_generator.classes\n    \n    print(\"Score = \", model.evaluate(data_generator))\n    print(\"Accuracy = \", metrics.accuracy_score(y_true, y_pred))\n    cm = metrics.confusion_matrix(y_true, y_pred)\n    metrics.ConfusionMatrixDisplay(cm, display_labels=CLASS_NAMES).plot(cmap=plt.cm.Blues,\n                                                                       xticks_rotation='vertical')\n    plt.show()\n\n    \ndef train_model():\n    \"\"\"\n    Trains VGG-19 model and saves the \n    trained weights to an H5 file.\n    Arguments: None\n    Returns: None\n    \"\"\"\n    \n    train_generator = load_data(TRAIN_PATH, True)\n    val_generator = load_data(TEST_PATH, True)\n    \n    # Loads VGG-19 model\n    model = load_model()\n    earlystop = keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-11, patience=10)\n    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, \n                                                   patience=6, verbose=1)\n    model_callbacks = [earlystop, reduce_lr]\n    \n    history = model.fit(\n        train_generator, \n        batch_size=BATCH_SIZE,\n        epochs=EPOCHS,\n        validation_data=val_generator,\n        validation_steps=val_generator.samples//BATCH_SIZE,\n        steps_per_epoch=train_generator.samples//BATCH_SIZE,\n        callbacks=model_callbacks)\n    \n    plot_curves(history)\n    model.save_weights(\"model_vgg19.h5\")\n    print(\"Model saved successfully!\")\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T06:36:13.374531Z","iopub.execute_input":"2021-11-07T06:36:13.374856Z","iopub.status.idle":"2021-11-07T06:36:13.445003Z","shell.execute_reply.started":"2021-11-07T06:36:13.374821Z","shell.execute_reply":"2021-11-07T06:36:13.443985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_sample_images()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nmodel = train_model()\nprint(\"Confusion matrix for train data: \")\nevaluate_model(model, TRAIN_PATH)\nprint(\"Confusion matrix for val data: \")\nevaluate_model(model, TEST_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T06:36:13.447064Z","iopub.execute_input":"2021-11-07T06:36:13.447432Z"},"trusted":true},"execution_count":null,"outputs":[]}]}