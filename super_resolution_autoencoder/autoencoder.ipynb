{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-06T14:46:53.612579Z",
     "iopub.status.busy": "2021-11-06T14:46:53.612309Z",
     "iopub.status.idle": "2021-11-06T14:46:53.648689Z",
     "shell.execute_reply": "2021-11-06T14:46:53.648012Z",
     "shell.execute_reply.started": "2021-11-06T14:46:53.612549Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Image Super-Resolution using Convolutional\n",
    "Autoencoders\n",
    "Author: Amruth Karun M V\n",
    "Date: 06-Nov-2021\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model, Input, regularizers\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Conv2D, MaxPool2D, \n",
    "    UpSampling2D, Add)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing import image\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "INPUT_PATH = '../input/cifar10/cifar10_sample/'\n",
    "\n",
    "def show_sample_image():\n",
    "    \"\"\"\n",
    "    Displays original 32 x 32 images.\n",
    "    Arguments: None\n",
    "    Returns: Displays the image\n",
    "    \"\"\"\n",
    "    \n",
    "    cifar_sample = glob.glob(INPUT_PATH + '*.png')\n",
    "    random_index = random.randint(0, 19)\n",
    "    print(\"Image: \", random_index)\n",
    "    img_path = cifar_sample[random_index]\n",
    "    img = cv2.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "        \n",
    "def load_images():\n",
    "    \"\"\"\n",
    "    Loads sample images from cifar10 dataset.\n",
    "    2 images are taken from each class. Total 20 images.\n",
    "    Arguments: None\n",
    "    Returns: Train and val images\n",
    "    \"\"\"\n",
    "    \n",
    "    cifar_sample = glob.glob(INPUT_PATH + '*.png')\n",
    "    print(\"Total images = \", len(cifar_sample))\n",
    "    all_images = []\n",
    "    for i in tqdm(cifar_sample):\n",
    "        img = image.load_img(i, target_size=(32,32,3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/255.\n",
    "        all_images.append(img)\n",
    "    all_images = np.array(all_images)\n",
    "    train_x, val_x = train_test_split(all_images, random_state=32, test_size=0.2)\n",
    "    return train_x, val_x\n",
    "\n",
    "def pixalate_image(image, scale_percent = 50):\n",
    "    \"\"\"\n",
    "    Lower the resolution of input image without\n",
    "    reducing the size\n",
    "    Arguments:\n",
    "        image         -- input image\n",
    "        scale_percent -- amount to be reduced\n",
    "    Returns: Pixalated image\n",
    "    \"\"\"\n",
    "    \n",
    "    width = int(image.shape[1] * scale_percent / 100)\n",
    "    height = int(image.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    small_image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    width = int(small_image.shape[1] * 100 / scale_percent)\n",
    "    height = int(small_image.shape[0] * 100 / scale_percent)\n",
    "    dim = (width, height)\n",
    "    low_res_image = cv2.resize(small_image, dim, interpolation = cv2.INTER_AREA)\n",
    "    return low_res_image\n",
    "\n",
    "\n",
    "def get_low_res_image(train_x, val_x):\n",
    "    \"\"\"\n",
    "    Get low resolution images for train\n",
    "    and validation set\n",
    "    Arguments:\n",
    "        train_x  -- train set\n",
    "        val_x    -- validation set\n",
    "    Returns: Low resolution data\n",
    "    \"\"\"\n",
    "    \n",
    "    # get low resolution images for the train set\n",
    "    train_x_px = []\n",
    "  \n",
    "    for i in range(train_x.shape[0]):\n",
    "        temp = pixalate_image(train_x[i,:,:,:])\n",
    "        train_x_px.append(temp)\n",
    "    train_x_px = np.array(train_x_px)   \n",
    "    \n",
    "    # get low resolution images for the validation set\n",
    "    val_x_px = []\n",
    "    for i in range(val_x.shape[0]):\n",
    "        temp = pixalate_image(val_x[i,:,:,:])\n",
    "        val_x_px.append(temp)\n",
    "    val_x_px = np.array(val_x_px)     \n",
    "    \n",
    "    return train_x_px, val_x_px\n",
    "\n",
    "def train_model(train_x_px, val_x_px):\n",
    "    \"\"\"\n",
    "    Trains the  Autoencoder network\n",
    "    Arguments: \n",
    "        train_x_px    -- low resolution train set\n",
    "        val_x_px      -- low resolution validation set\n",
    "    Returns: Autoencoder Network\n",
    "    \"\"\"\n",
    "    \n",
    "    Input_img = Input(shape=(32, 32, 3))  \n",
    "    #encoding architecture\n",
    "    x1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(Input_img)\n",
    "    x2 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x1)\n",
    "    x3 = MaxPool2D(padding='same')(x2)\n",
    "    x4 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x3)\n",
    "    x5 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x4)\n",
    "    x6 = MaxPool2D(padding='same')(x5)\n",
    "    encoded = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x6)\n",
    "    \n",
    "    # decoding architecture\n",
    "    x7 = UpSampling2D()(encoded)\n",
    "    x8 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x7)\n",
    "    x9 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x8)\n",
    "    x10 = Add()([x5, x9])\n",
    "    x11 = UpSampling2D()(x10)\n",
    "    x12 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x11)\n",
    "    x13 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x12)\n",
    "    x14 = Add()([x2, x13])\n",
    "    decoded = Conv2D(3, (3, 3), padding='same',activation='relu', kernel_regularizer=regularizers.l1(10e-10))(x14)\n",
    "    autoencoder = Model(Input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    autoencoder.summary()\n",
    "    \n",
    "    early_stopper = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=8, verbose=1, mode='auto')\n",
    "    history = autoencoder.fit(train_x_px, train_x,\n",
    "                              epochs=256,\n",
    "                              batch_size=64,\n",
    "                              shuffle=True,\n",
    "                              validation_data=(val_x_px, val_x),\n",
    "                              callbacks=[early_stopper])\n",
    "    \n",
    "    autoencoder.save_weights(\"autoencoder.h5\")\n",
    "    return autoencoder\n",
    "\n",
    "def get_results(autoencoder, val_x, val_x_px):\n",
    "    \"\"\"\n",
    "    Evaluate the autoencoder model using\n",
    "    validation data and predict results\n",
    "    Arguments:\n",
    "        autoencoder    -- trained autoencoder model\n",
    "        val_x          -- original validation data\n",
    "        val_x_px       -- low resolution validation data\n",
    "    \"\"\"\n",
    "    \n",
    "    results = autoencoder.evaluate(val_x_px, val_x)\n",
    "    print('val_loss = {}, val_accuracy = {}'.format(results[0], results[1]))\n",
    "    \n",
    "    predictions = autoencoder.predict(val_x_px)\n",
    "    \n",
    "    n = 4\n",
    "    plt.figure(figsize= (20,10))\n",
    "    for i in range(n):\n",
    "        ax1 = plt.subplot(3, n, i+1)\n",
    "        plt.imshow(val_x_px[i])\n",
    "        ax1.get_xaxis().set_visible(False)\n",
    "        ax1.get_yaxis().set_visible(False)\n",
    "        ax1.title.set_text('Pixelated Image')\n",
    "        \n",
    "        ax2 = plt.subplot(3, n, i+1+n)\n",
    "        plt.imshow(predictions[i])\n",
    "        ax2.get_xaxis().set_visible(False)\n",
    "        ax2.get_yaxis().set_visible(False)\n",
    "        ax2.title.set_text('Predicted Image')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-06T14:46:53.650374Z",
     "iopub.status.busy": "2021-11-06T14:46:53.649844Z",
     "iopub.status.idle": "2021-11-06T14:47:28.223388Z",
     "shell.execute_reply": "2021-11-06T14:47:28.222715Z",
     "shell.execute_reply.started": "2021-11-06T14:46:53.650342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show 1 random image from train set\n",
    "# show_sample_image()\n",
    "train_x, val_x = load_images()\n",
    "train_x_px, val_x_px = get_low_res_image(train_x, val_x) \n",
    "\n",
    "# Train the model\n",
    "autoencoder = train_model(train_x_px, val_x_px)\n",
    "get_results(autoencoder, val_x, val_x_px)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
